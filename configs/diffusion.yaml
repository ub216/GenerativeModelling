experiment:
  name: "Generative"

model:
  type: "diffusion"                     # options: vae, diffusion, flow, etc.
  params:
    timesteps: 1000
    test_timesteps: 1000
    renormalise: true
    text_emb_dim: null                   # Set to null if CFG not required
    sample_condition_weight: 10
  checkpoint: null                      # Use for evaluation or restarting training

optimizer:                              
  type: "adam"                          
  params:
    lr: 0.001
    weight_decay: 0.0
  accumulate_steps: 1                   # Number of steps to accumulate gradients over  

training:
  batch_size: 64
  epochs: 50
  device: "cuda"
  metric_interval: 500
  save_after_epoch: -1  

evaluation:
  samples: 100                          # Only used for evaluation run
    
dataset:
  type: "mnist"                         # options: mnist (imagenet, coco, .. in future)
  params:
    root: "/data/datasets/mnist/"
    num_workers: 8
    pin_memory: true
    persistent_workers: true

loss:
  type: "pair_mse"                      # options: vae_loss, pair_mse
  params:
    reduction: "mean"

metrics:
  fid:
    type: "fid_inception"
    params: 
      samples: 8000